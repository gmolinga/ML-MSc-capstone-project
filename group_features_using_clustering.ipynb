{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "736c7ed2",
   "metadata": {},
   "source": [
    "# Capstone project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1b805",
   "metadata": {
    "id": "10b1b805"
   },
   "outputs": [],
   "source": [
    "#librerías estandarizar y crear clusters\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations,product,chain\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignorar todos los warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "RANDOM_SEED = 1\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2829068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "c2829068",
    "outputId": "6083ed68-a4ab-401f-9562-bd1e063eea00"
   },
   "outputs": [],
   "source": [
    "#sitio BBDD Helena\n",
    "#df=pd.read_csv('data/datos_income_TFM.csv', sep= ',')\n",
    "\n",
    "df = pd.read_csv('data/datos_income_TFM.csv', sep=',')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar variable redundante edad diagnóstico diabetes\n",
    "\n",
    "df = df.drop(columns=['DIABAGE3', 'X.AGE80'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78e467",
   "metadata": {
    "id": "8a78e467",
    "outputId": "f1b55ce0-4d40-405e-f932-4d8d2563cabc"
   },
   "outputs": [],
   "source": [
    "# Crear variable BMI y ponerla en intervalos: Peso y altura vienen en sistema anglosajón\n",
    "\n",
    "df['BMI_WHO']=df['WEIGHT2']/df['HEIGHT3']**2*10000\n",
    "df['BMI_WHO']=df['BMI_WHO'].round().astype('int')\n",
    "df['BMI_WHO']=pd.cut(df['BMI_WHO'],bins=[0,18.5,25,30,35,40,df['BMI_WHO'].max()],\n",
    "                     labels=range(1,7),\n",
    "                     include_lowest=True,ordered=True)\n",
    "df['BMI_WHO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a4577-da49-45a2-8056-dc88fa5c80ca",
   "metadata": {
    "id": "034a4577-da49-45a2-8056-dc88fa5c80ca",
    "outputId": "609732c5-fad3-44a3-a8e3-9f54c338a4d9"
   },
   "outputs": [],
   "source": [
    "# one hot encoding del BMI\n",
    "'''\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = encoder.fit_transform(df[['BMI_WHO']])\n",
    "# Crear un DataFrame a partir de la matriz codificada\n",
    "df_encoded = pd.DataFrame(onehot_encoded, columns=encoder.get_feature_names(['BMI_WHO']))\n",
    "df_concat = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# poner en enteros las 6 nuevas columnas de BMI\n",
    "columnas = ['BMI_WHO_1', 'BMI_WHO_2','BMI_WHO_3','BMI_WHO_4','BMI_WHO_5','BMI_WHO_6']\n",
    "for col in columnas:\n",
    "    df_concat[col] = df_concat[col].round().astype('int')\n",
    "\n",
    "df_concat'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fd62d64-e9b6-494b-a474-32e976bd4bb1",
   "metadata": {
    "id": "8fd62d64-e9b6-494b-a474-32e976bd4bb1"
   },
   "source": [
    "# Partición train, validation y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20489f44-b976-49a4-8319-7670583a80ff",
   "metadata": {
    "id": "20489f44-b976-49a4-8319-7670583a80ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target = \"DIABETE4\"\n",
    "\n",
    "x = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# Conjunto de entrenamiento del 60%\n",
    "x_temp, x_train, y_temp, y_train = train_test_split(x, y, test_size=0.60, random_state=RANDOM_SEED)\n",
    "\n",
    "# Conjuntos de validación y prueba (cada uno del 20% del total)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.50, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc50d2",
   "metadata": {
    "id": "aacc50d2",
    "outputId": "dfe99400-01ff-4f68-f843-2d0367b8cf63"
   },
   "outputs": [],
   "source": [
    "### Estandarizar el train\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_s=pd.DataFrame(scaler.transform(x_train),\n",
    "                           index=x_train.index,columns=x_train.columns)\n",
    "x_train_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765c9d1",
   "metadata": {
    "id": "f765c9d1",
    "outputId": "1161458a-eb25-452e-da9b-8a31ccb765ab"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7190a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estandarizar x_test y x_val\n",
    "\n",
    "scaler2=StandardScaler()\n",
    "scaler2.fit(x_test)\n",
    "\n",
    "x_test_s=pd.DataFrame(scaler2.transform(x_test),\n",
    "                           index=x_test.index,columns=x_test.columns)\n",
    "\n",
    "scaler3=StandardScaler()\n",
    "scaler3.fit(x_val)\n",
    "x_val_s = pd.DataFrame(scaler3.transform(x_val),\n",
    "                           index=x_val.index,columns=x_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850de287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitar variables redundantes con feature wiz, edad diagnóstico de diabetes, edad y BMI en continuo\n",
    "\n",
    "import featurewiz as fwiz\n",
    "\n",
    "outputs = fwiz.featurewiz(dataname=df, target=target, corr_limit=0.85, verbose=1, sep=',', \n",
    "\t\theader=0,  \n",
    "\t\tdask_xgboost_flag=False, nrows=None, skip_sulov=False, skip_xgboost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get list of selected features ###\n",
    "features, df2 = outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00263b8d",
   "metadata": {
    "id": "00263b8d"
   },
   "source": [
    "## Transponer filas y columnas en train\n",
    "\n",
    "Para hacer clustering de variables en vez de personas, hay que transponer filas y columnas, de este modo, las variables pasan a ser las \"observaciones\" y las personas, características similares en función de los que luego hacer los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd07e158-9894-4109-a199-93650b2cfde3",
   "metadata": {
    "id": "cd07e158-9894-4109-a199-93650b2cfde3"
   },
   "outputs": [],
   "source": [
    "x_train_transposed = x_train_s.T\n",
    "#df_standard_T\n",
    "# Transponer filas y columnas\n",
    "#df_standard_T = standard_data.transpose() #esta es la que ha usado Helena\n",
    "#df_standard_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddaa503",
   "metadata": {
    "id": "5ddaa503",
    "outputId": "26ba5122-efbb-4814-e8ce-8403fe2f1f0b"
   },
   "outputs": [],
   "source": [
    "## Segunda tanda de estandarización, ahora por pacientes,\n",
    "#esta nos la saltamos\n",
    "'''\n",
    "scaler2=StandardScaler() #nuevo objeto scaler\n",
    "scaler2.fit(df_standard_T)\n",
    "\n",
    "df_T_standard=pd.DataFrame(scaler2.transform(df_standard_T),\n",
    "                           index=df_standard_T.index,columns=df_standard_T.columns)\n",
    "df_T_standard'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "128ebb8d",
   "metadata": {
    "id": "128ebb8d"
   },
   "source": [
    "# Crear clusters sin morir en el intento\n",
    "\n",
    "Clustering techniques to be used:\n",
    "- K-means. It is a clustering algorithm based on partitioning that groups data into k distinct groups.\n",
    "\n",
    "Indices to be used:¶\n",
    "- Silhouette Coefficient. This index measures intra-cluster cohesion and inter-cluster separation. It provides a value between -1 and 1, where values closer to 1 indicate good separation between clusters and values closer to -1 indicate poor separation. It is widely used to assess the quality of clustering.\n",
    "\n",
    "- Calinski-Harabasz Index. This index calculates the ratio between intra-cluster dispersion and inter-cluster dispersion. Higher values of the index indicate better separation between clusters.\n",
    "\n",
    "- Davies-Bouldin Index. This index measures the average similarity between each cluster and its nearest cluster. A lower value of the index indicates better separation between clusters.\n",
    "\n",
    "- Dunn Index. This index measures the ratio between the minimum distance between clusters and the maximum distance within each cluster. Higher values of the index indicate better separation between clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79915137",
   "metadata": {
    "id": "79915137"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f58104",
   "metadata": {
    "id": "19f58104"
   },
   "outputs": [],
   "source": [
    "#Hyperparameters #este método tiende a encontrar 2 clusters, quitar esa opción\n",
    "param_grid = {\n",
    "    'n_clusters': [2],  # Different numbers of clusters to be assessed\n",
    "    'init': ['k-means++'], #random # Different initialisation methods\n",
    "    'max_iter': [100] #200 #300 # Different maximum number of iterations\n",
    "}\n",
    "\n",
    "# Evaluation indices\n",
    "\n",
    "evaluation_indices = {\n",
    "    'Silhouette Coefficient': silhouette_score,\n",
    "    'Calinski-Harabasz Index': calinski_harabasz_score,\n",
    "    'Davies-Bouldin Index': davies_bouldin_score\n",
    "}\n",
    "\n",
    "def dunn_index(data, labels):\n",
    "    distances = pairwise_distances(data)\n",
    "    intra_cluster_distances = []\n",
    "    for label in set(labels):\n",
    "        cluster_points = data[labels == label]\n",
    "        cluster_distances = distances[labels == label][:, labels == label]\n",
    "        intra_cluster_distances.append(cluster_distances.max())\n",
    "    min_inter_cluster_distance = distances[labels != labels[:, None]].min()\n",
    "    dunn_index = min_inter_cluster_distance / max(intra_cluster_distances)\n",
    "    return dunn_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997468b5",
   "metadata": {
    "id": "997468b5"
   },
   "outputs": [],
   "source": [
    "# Ajustar KMeans antes de aplicar GridSearchCV, tarda sus 30-45 min tranquilamente\n",
    "'''kmeans = KMeans()  # Crea una instancia de KMeans\n",
    "kmeans.fit(df_T_standard)  # Ajusta KMeans a tus datos\n",
    "\n",
    "# Apply GridSearchCV to find the best hyperparameters.\n",
    "grid_search = GridSearchCV(kmeans, param_grid, scoring=silhouette_score, cv=5)\n",
    "grid_search.fit(df_T_standard)\n",
    "best_params = grid_search.best_params_'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176886ee-2340-44a7-b9d7-4273689bfc40",
   "metadata": {
    "id": "176886ee-2340-44a7-b9d7-4273689bfc40",
    "outputId": "349856aa-d51a-4781-e518-a21037fd8903"
   },
   "outputs": [],
   "source": [
    "# Probar otro índice - Guillem\n",
    "\n",
    "'''# Ajustar KMeans para pruebas de 2 a 10 clusters, sin hacer gridsearch\n",
    "results =[]\n",
    "\n",
    "for i in range(2,20):\n",
    "    kmeans2 = KMeans(n_clusters=i, init= 'k-means++',\n",
    "                     max_iter=100, random_state=1)  # Crea una instancia de KMeans\n",
    "    kmeans2.fit(df_standard_T)\n",
    "    results.append(kmeans2.inertia_)# Ajusta KMeans a tus datos\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.plot(range(2, 20), results)\n",
    "plt.title('Método del codo')\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Inercia')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5a873-5ac3-443d-8422-b9eec84a8401",
   "metadata": {
    "id": "e4a5a873-5ac3-443d-8422-b9eec84a8401",
    "outputId": "4086e369-8d9d-42c2-fc35-60a454fab991"
   },
   "outputs": [],
   "source": [
    "'''# Computar los clusters y el\n",
    "\n",
    "    # Calculate the evaluation indices.\n",
    "scores = {'Datos_kmeans': f'Datos_{1}_kmeans', 'Numero_Clusters': num_clusters,\n",
    "          'init':best_params['init'], 'max_iter': best_params['max_iter']}\n",
    "# Ajustar KMeans para pruebas de 2 a 10 clusters, sin hacer gridsearch\n",
    "results2 =[]\n",
    "\n",
    "for i in range(6,9):\n",
    "    kmeans3 = KMeans(n_clusters=i, init= 'k-means++',\n",
    "                     max_iter=300, random_state=1)  # Crea una instancia de KMeans\n",
    "    kmeans3.fit(df_T_standard) # Ajusta KMeans a tus datos\n",
    "    results.append(kmeans3.inertia_)\n",
    "    labels2=kmeans3.labels_\n",
    "\n",
    "\n",
    "    for index_name, index_func in evaluation_indices.items():\n",
    "        score = index_func(df_T_standard, labels)\n",
    "        scores[index_name] = score\n",
    "\n",
    "    # Calculate the Dunn and Hopkins indices.\n",
    "    dunn = dunn_index(df_T_standard, labels)\n",
    "    scores['Dunn Index'] = dunn'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a1b89-a7d2-4349-a44c-842e5dd1124c",
   "metadata": {
    "id": "489a1b89-a7d2-4349-a44c-842e5dd1124c",
    "outputId": "e69c71ca-56a2-45d6-ce13-8fc758a11e3f"
   },
   "outputs": [],
   "source": [
    "# calcular scores para 2 a 9 clusters\n",
    "\n",
    "    # Calculate the evaluation indices.\n",
    "#scores = {'Datos_kmeans': f'Datos_{1}_kmeans', 'Numero_Clusters': num_clusters,\n",
    "        #  'init':best_params['init'], 'max_iter': best_params['max_iter']}\n",
    "\n",
    "resultados = []  # Crear una lista vacía para almacenar los resultados\n",
    "\n",
    "x_train_transposed.columns = x_train_transposed.columns.astype(str)\n",
    "\n",
    "for i in range(2,10):\n",
    "    kmeans3 = KMeans(n_clusters=i, init= 'k-means++', max_iter=100, random_state=1)  # Crea una instancia de KMeans\n",
    "    kmeans3.fit(x_train_transposed) # Ajusta KMeans a tus datos\n",
    "    labels2 = kmeans3.labels_  # Obtiene las etiquetas del ajuste actual de KMeans\n",
    "\n",
    "    # Añadir las etiquetas al DataFrame como una nueva columna\n",
    "    x_train_transposed['Cluster_' + str(i)] = labels2\n",
    "\n",
    "    # Imprimir la frecuencia de observaciones por cluster\n",
    "    print(f\"Frecuencia de observaciones para {i} clusters:\")\n",
    "    print(x_train_transposed['Cluster_' + str(i)].value_counts())\n",
    "\n",
    "    # Crear un histograma de las distribuciones\n",
    "    pal = [\"#682F2F\",\"#B9C0C9\", \"#9F8A78\",\"#F3AB60\"]\n",
    "    sns.countplot(x=x_train_transposed['Cluster_' + str(i)], palette= pal)\n",
    "    plt.title(f\"Distribución de los clusters para {i} clusters\")\n",
    "    plt.xlabel(\"Cluster\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n",
    "\n",
    "    # Crear un nuevo diccionario para almacenar los resultados de esta iteración\n",
    "    scores = {}\n",
    "\n",
    "    for index_name, index_func in evaluation_indices.items():\n",
    "        score = index_func(x_train_transposed.drop(['Cluster_' + str(i)], axis=1), labels2)  # Usa las etiquetas actuales\n",
    "        scores[index_name] = score\n",
    "\n",
    "    # Calcular los índices de Dunn y Hopkins.\n",
    "    dunn = dunn_index(x_train_transposed.drop(['Cluster_' + str(i)], axis=1), labels2)  # Usa las etiquetas actuales\n",
    "    scores['Dunn Index'] = dunn\n",
    "\n",
    "    # Añadir los resultados de esta iteración a la lista de resultados\n",
    "    resultados.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642aa208-4fc6-4f04-91ff-6cb86e22762c",
   "metadata": {
    "id": "642aa208-4fc6-4f04-91ff-6cb86e22762c"
   },
   "outputs": [],
   "source": [
    "#uy ojo.. que sin estandarizar la segunda vez están saliendo clusters distribuidos!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faad45-410f-48ce-9107-acfb16d836b2",
   "metadata": {
    "id": "e4faad45-410f-48ce-9107-acfb16d836b2",
    "outputId": "16091766-8818-4fff-d263-6edc22732ad0"
   },
   "outputs": [],
   "source": [
    "tabla_resultados = pd.DataFrame(resultados)\n",
    "tabla_resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8abcbb9e",
   "metadata": {},
   "source": [
    "Visualización de los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0bec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import umap # pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_k = 8\n",
    "kmeans = KMeans(n_clusters=8, init= 'k-means++', max_iter=100, random_state=1)  # Crea una instancia de KMeans\n",
    "kmeans.fit(x_train_transposed) # Ajusta KMeans a tus datos\n",
    "labels = kmeans.labels_  # Obtiene las etiquetas del ajuste actual de KMeans\n",
    "\n",
    "# Añadir las etiquetas al DataFrame como una nueva columna\n",
    "x_train_transposed[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8203db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "x_embedded_with_tsne = tsne.fit_transform(x_train_transposed.drop(columns=\"cluster\"))\n",
    "vis_data = pd.DataFrame(x_embedded_with_tsne, index=x_train_transposed.index)\n",
    "vis_data[\"cluster\"] = x_train_transposed[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=0, y=1, hue=\"cluster\", data=vis_data, palette=sns.color_palette(\"hls\", 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded_with_umap = umap.UMAP(n_neighbors=8, random_state=42).fit(x_train_transposed.drop(columns=\"cluster\"))\n",
    "vis_data = pd.DataFrame(x_embedded_with_umap.embedding_, index=x_train_transposed.index)\n",
    "vis_data[\"cluster\"] = x_train_transposed[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=0, y=1, hue=\"cluster\", data=vis_data, palette=sns.color_palette(\"hls\", 8)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02044358",
   "metadata": {},
   "source": [
    "Otro paso: automatizar la selección del mejor número de clusters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Otro paso: automatizar la selección del mejor número de clusters'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144744e7-9784-4786-af2c-c9a2dd299495",
   "metadata": {
    "id": "144744e7-9784-4786-af2c-c9a2dd299495"
   },
   "outputs": [],
   "source": [
    "x_train_transposed.to_csv('Datos_TFM_columnasclusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd23b86-99cf-4922-9e48-73a5d3b20469",
   "metadata": {
    "id": "afd23b86-99cf-4922-9e48-73a5d3b20469",
    "outputId": "47109726-0772-4d65-afaf-bf978d71cd8d"
   },
   "outputs": [],
   "source": [
    "x_train_transposed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de05ce",
   "metadata": {
    "id": "72de05ce"
   },
   "outputs": [],
   "source": [
    "# Get the best model with the selected hyperparameters.\n",
    "'''best_model = KMeans(**best_params)\n",
    "best_model.fit(df_T_standard)\n",
    "labels = best_model.labels_\n",
    "num_clusters = len(set(labels))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81203a45",
   "metadata": {
    "id": "81203a45",
    "outputId": "f895fc1b-b801-44df-977f-6b0758088417"
   },
   "outputs": [],
   "source": [
    "'''# Calculate the evaluation indices.\n",
    "scores = {'Datos_kmeans': f'Datos_{1}_kmeans', 'Numero_Clusters': num_clusters,\n",
    "          'init':best_params['init'], 'max_iter': best_params['max_iter']}\n",
    "for index_name, index_func in evaluation_indices.items():\n",
    "    score = index_func(df_T_standard, labels)\n",
    "    scores[index_name] = score\n",
    "\n",
    "# Calculate the Dunn and Hopkins indices.\n",
    "dunn = dunn_index(df_T_standard, labels)\n",
    "scores['Dunn Index'] = dunn\n",
    "\n",
    "\n",
    "scores'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb441f",
   "metadata": {
    "id": "32eb441f"
   },
   "outputs": [],
   "source": [
    "'''nueva_fila = pd.DataFrame([scores], columns=['Datos_kmeans', 'Numero_Clusters', 'init', 'max_iter']\n",
    "                          + list(evaluation_indices.keys()) + ['Dunn Index'])\n",
    "\n",
    "# Add the results to the dataframe\n",
    "k_means_df = pd.concat([df_T_standard, nueva_fila], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "k_means_df.to_csv('kmeans_results.csv', index=False)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057d287",
   "metadata": {
    "id": "5057d287"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec102264",
   "metadata": {
    "id": "ec102264"
   },
   "outputs": [],
   "source": [
    "'''#Adding the Clusters feature to the original dataframe.\n",
    "df_T_standard[\"clusters\"]= best_model.fit_predict(df_T_standard)\n",
    "df_T_standard[\"clusters\"]= df_T_standard[\"clusters\"].astype('category')\n",
    "\n",
    "clusters_df = df_T_standard.copy()\n",
    "\n",
    "# Save the results to a CSV file\n",
    "#clusters_df.to_csv('clusters_results.csv', index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e228f70-b165-474a-8892-544f30a10fa8",
   "metadata": {
    "id": "1e228f70-b165-474a-8892-544f30a10fa8",
    "outputId": "520b997d-4162-4e31-cda7-2080a63a2a7b"
   },
   "outputs": [],
   "source": [
    "## Crear un diccionario con las variables de nuestro cluster de elección:  clúster 8\n",
    "\n",
    "unicos8 = x_train_transposed['Cluster_8'].unique()\n",
    "\n",
    "diccionario8 = {}\n",
    "\n",
    "for valor in unicos8:\n",
    "    filas = x_train_transposed.index[x_train_transposed['Cluster_8'] == valor].tolist()\n",
    "    diccionario8[valor] = filas\n",
    "\n",
    "# Ver el diccionario\n",
    "for clave, valor in diccionario8.items():\n",
    "    print(f'Valor: {clave} - Filas: {valor}')\n",
    "\n",
    "df_cluster8 = pd.DataFrame.from_dict(diccionario8, orient='index')\n",
    "df_cluster8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbac1f9-40c6-4dd6-9b00-1d23f57f41fe",
   "metadata": {
    "id": "4fbac1f9-40c6-4dd6-9b00-1d23f57f41fe",
    "outputId": "af594484-4ba5-41de-c1e5-ed7726a8eb16"
   },
   "outputs": [],
   "source": [
    "diccionario8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f58ed-f424-4091-8030-c51b0a95efb4",
   "metadata": {
    "id": "5f1f58ed-f424-4091-8030-c51b0a95efb4",
    "outputId": "99645b66-e0bd-464e-e9c8-1470f3c71b40"
   },
   "outputs": [],
   "source": [
    "diccionario8.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd134b29-fc34-482c-b9b3-5ecaf12f0ed3",
   "metadata": {
    "id": "cd134b29-fc34-482c-b9b3-5ecaf12f0ed3",
    "outputId": "a05bfecb-7b0b-4a79-db54-785078f19015"
   },
   "outputs": [],
   "source": [
    "dict(zip(('a','b','c'),(11,44,77)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74345d1-e5e4-40af-865f-9faee1521bd5",
   "metadata": {
    "id": "c74345d1-e5e4-40af-865f-9faee1521bd5",
    "outputId": "9c89fac3-e600-4e30-8c07-20ac14070cf2"
   },
   "outputs": [],
   "source": [
    "'''crear otro diccionario que te de máximo 1/3 de la longitud del\n",
    "diccionario original'''\n",
    "\n",
    "diccionario_sizes=dict(zip(diccionario8,\n",
    "            [max(1,int(len(g)/3)) for g in diccionario8.values()]))\n",
    "\n",
    "#sobreescribimos y le decimos que coja máximo 1 vv de cada set\n",
    "#diccionario_sizes=dict(zip(diccionario8,[1]*len(diccionario8)))\n",
    "#diccionario_sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "039a7355",
   "metadata": {},
   "source": [
    "## Una estrategia: \n",
    "Coger los mejores representantes de cada cluster: que esas 6,1, 2... que coja de cada cluster, sean las que tengan la MI/corr() más alta con nuestro predictor, o quédate solo con la mitad de cada caja con corr()/MI más alta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Contenedor para los mejores predictores de cada cluster\n",
    "best_predictors = {}\n",
    "\n",
    "# Diccionario de clusters\n",
    "diccionario8  # Tu diccionario aquí\n",
    "\n",
    "# df de variables predictoras\n",
    "x_val_s  # Tu DataFrame aquí\n",
    "\n",
    "for cluster_name, predictors in diccionario8.items():\n",
    "    # Subconjunto de df para el cluster actual\n",
    "    cluster = x_val_s[predictors]\n",
    "\n",
    "    # Calcula la MI de cada feature en el cluster con el target\n",
    "    mi = mutual_info_classif(cluster, y_val)\n",
    "    \n",
    "    # Crea un df con los resultados\n",
    "    mi_df = pd.DataFrame({\n",
    "        'variable': cluster.columns,\n",
    "        'mi': mi\n",
    "    })\n",
    "\n",
    "    # Ordena el df por MI en orden descendente\n",
    "    mi_df = mi_df.sort_values(by='mi', ascending=False)\n",
    "    \n",
    "    # Selecciona el 50% superior de las variables\n",
    "    top_50_percent = mi_df[:len(mi_df)//2]\n",
    "    \n",
    "    # Número máximo de features a seleccionar basado en el tamaño del cluster\n",
    "    max_predictors = min(len(cluster.columns), 6)\n",
    "    \n",
    "    # Selecciona las `max_predictors` variables con mayor Información Mutua\n",
    "    top_predictors = top_50_percent[:max_predictors]\n",
    "    \n",
    "    # Agrega las mejores variables al diccionario de mejores predictores\n",
    "    best_predictors[cluster_name] = top_predictors['variable'].tolist()\n",
    "\n",
    "# Ahora `best_predictors` es un diccionario con los nombres de las mejores variables de cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a15fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictors\n",
    "#Esto ya hace que las combis se hagan con unas 35 vv en vez de con 78..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8114f584",
   "metadata": {},
   "source": [
    "# Generación de combinaciones de regresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69092071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir el mínimo y máximo número de features predictoras que tendrá el modelo\n",
    "#n_min=len(diccionario8)\n",
    "#n_max=2*len(diccionario8)\n",
    "n_min=2\n",
    "n_max=10\n",
    "n_min, n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23392024-8e21-455c-a7f4-a5a51501e9e0",
   "metadata": {
    "id": "23392024-8e21-455c-a7f4-a5a51501e9e0"
   },
   "outputs": [],
   "source": [
    "def get_custom_combinations(grouped_cols_list,max_sizes_list,n_min=None,n_max=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate all possible combinations of variables from the specified groups,\n",
    "    while limiting the number of variables from each group based on max_sizes_list.\n",
    "    Each combination must have at least n_min variables and at most n_max variables.\n",
    "\n",
    "    :param grouped_cols_list: A list of lists, where each sublist represents a\n",
    "    group of variables.\n",
    "    :param max_sizes_list: A list of integers representing the maximum number\n",
    "    of variables allowed from each group.\n",
    "    :param n_max: The maximum total number of variables allowed in a combination.\n",
    "    :param n_min: The minimum total number of variables allowed in a combination\n",
    "    :return: A list of lists, where each sublist is a valid combination of variables.\n",
    "    \"\"\"\n",
    "\n",
    "    def combinations_by_group_and_max_size(group,max_size):\n",
    "        \"\"\"\n",
    "        Generate all combinations of variables in a group, with a maximum size\n",
    "        of max_size.\n",
    "\n",
    "        :param group: A list of variables.\n",
    "        :param max_size: The maximum number of variables to include in a combination.\n",
    "        :return: A list of lists, where each sublist is a combination of variables.\n",
    "        \"\"\"\n",
    "        print(f\"Group: {group}, type: {type(group)}\")\n",
    "        print(f\"Max size: {max_size}, type: {type(max_size)}\")\n",
    "        return [list(c) for size in range(max_size+1) for c in combinations(group,size)]\n",
    "\n",
    "    # Generate all valid combinations for each group:\n",
    "    aux=list(map(lambda tuple_:combinations_by_group_and_max_size(*tuple_),\n",
    "                 zip(grouped_cols_list,max_sizes_list)))\n",
    "\n",
    "    # Generate all possible combinations of the combinations from each group:\n",
    "    out=[list(chain(*g)) for g in product(*aux)]\n",
    "\n",
    "    # Filter combinations to ensure they have between n_min and n_max variables:\n",
    "    out=[o for o in out if (n_min is None or n_min<=len(o))\n",
    "         and (n_max is None or len(o)<=n_max)]\n",
    "\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ad022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrategia de generar combinaciones con la selección previa en base a top valores MI\n",
    "\n",
    "# con best_predictors\n",
    "\n",
    "custom_combis = get_custom_combinations(list(best_predictors.values()),\n",
    "                        list(diccionario_sizes.values()),n_min,n_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mirar numero de combinaciones\n",
    "\n",
    "len(custom_combis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Función optimizada con un generador, que produce cada combinación\n",
    "a medida que se solicite en lugar de todas a la vez'''\n",
    "\n",
    "def get_custom_combinations_opt(grouped_cols_list, max_sizes_list, n_min=None, n_max=None):\n",
    "    def combinations_by_group_and_max_size(group, max_size):\n",
    "        for size in range(max_size+1):\n",
    "            for c in combinations(group, size):\n",
    "                yield list(c)\n",
    "\n",
    "    # Generate all valid combinations for each group:\n",
    "    aux=[combinations_by_group_and_max_size(group, max_size) \n",
    "        for group, max_size in zip(grouped_cols_list, max_sizes_list)]\n",
    "\n",
    "    # Generate all possible combinations of the combinations from each group:\n",
    "    for g in product(*aux):\n",
    "        combined = list(chain(*g))\n",
    "\n",
    "        # Filter combinations to ensure they have between n_min and n_max variables:\n",
    "        if (n_min is None or n_min <= len(combined)) and (n_max is None or len(combined) <= n_max):\n",
    "            yield combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d346e20-0724-4d5a-b71b-6dfab2cc1a00",
   "metadata": {
    "id": "2d346e20-0724-4d5a-b71b-6dfab2cc1a00",
    "outputId": "af953e96-e641-4750-c30c-6582bd6f8198"
   },
   "outputs": [],
   "source": [
    "#Definir el mínimo y máximo número de features predictoras que tendrá el modelo\n",
    "n_min=len(diccionario8)\n",
    "n_max=2*len(diccionario8)\n",
    "n_min, n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_combis_opt = get_custom_combinations_opt(list(diccionario8.values()),\n",
    "                        list(diccionario_sizes.values()),n_min,n_max)\n",
    "\n",
    "custom_combis_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "['X.STATE', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'MEDCOST', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW', 'ADDEPEV3', 'DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'FALL12MN', 'HIVRISK5', 'CIMEMLOS', 'MARITAL.5', 'RENTHOM1.3', 'EMPLOY1.3', 'EMPLOY1.8', 'X.IMPRACE.5']\n",
    "['SEXVAR', 'GENHLTH', 'HLTHPLN1', 'PERSDOC2', 'CHECKUP1', 'EXERANY2', 'SLEPTIM1', 'LASTDEN4', 'EDUCA', 'FLUSHOT7', 'SEATBELT', 'EMPLOY1.1', 'EMPLOY1.6']\n",
    "['CHCSCNCR', 'CHCOCNCR', 'HAVARTH4', 'CHCKDNY2', 'X.AGEG5YR', 'X.AGE80', 'MARITAL.3', 'EMPLOY1.7', 'VO_CORAZON']\n",
    "['CHCCOPD2', 'RMVTETH4', 'SMOKE100', 'SMOKDAY2', 'ECIGNOW', 'LCSLAST', 'LCSNUMCG', 'MARITAL.2', 'MARITAL.4', 'MARITAL.6', 'RENTHOM1.2', 'EMPLOY1.4', 'X.IMPRACE.4', 'X.IMPRACE.6']\n",
    "['DIABAGE3', 'WEIGHT2', 'X.IMPRACE.2', 'BMI', 'BMI_WHO']\n",
    "['CHILDREN', 'X.INCOMG', 'MARITAL.1', 'RENTHOM1.1', 'EMPLOY1.2', 'EMPLOY1.5', 'X.IMPRACE.1', 'X.IMPRACE.3']\n",
    "['HEIGHT3', 'USENOW3', 'ALCDAY5', 'DRNK3GE5', 'MAXDRNKS', 'LCSFIRST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf199f-491a-48cb-bc3d-27c7a74fd0df",
   "metadata": {
    "id": "93cf199f-491a-48cb-bc3d-27c7a74fd0df"
   },
   "outputs": [],
   "source": [
    "all_combis = [\n",
    "    ['X.STATE', 'SEXVAR','CHCSCNCR','X.AGEG5YR'],\n",
    "    ['X.STATE', 'SEXVAR','CHCSCNCR','X.AGEG5YR','CHILDREN'],\n",
    "    ['X.STATE', 'SEXVAR','CHCSCNCR','X.AGEG5YR','HEIGHT3'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estrategia de V3\n",
    "\n",
    "#RF pequeño, para evitar overfitting\n",
    "\n",
    "hyperparameters = {'n_estimators':10,  # Número reducido de árboles\n",
    "    'max_depth':5,  # Profundidad máxima limitada\n",
    "    'min_samples_split':20,  # Mayor número mínimo de muestras para dividir un nodo\n",
    "    'min_samples_leaf':10,\n",
    "    'max_features': 'auto',\n",
    "    'bootstrap': True,\n",
    "    'oob_score':True}\n",
    "\n",
    "                  \n",
    "results = []\n",
    "\n",
    "for combi in tqdm(custom_combis): #no falta la cross-validation?\n",
    "    model = RandomForestClassifier(**hyperparameters)\n",
    "    model.fit(x_train_s[combi], y_train)\n",
    "    y_pred_train = model.predict(x_train_s[combi])\n",
    "    y_pred_val = model.predict(x_val_s[combi])\n",
    "    metadata = {\n",
    "        \"Combination\":combi,\n",
    "        \"Hyperparameters\":hyperparameters,\n",
    "        \"AccuracyTrain\":accuracy_score(y_train, y_pred_train),\n",
    "        \"AccuracyTest\":accuracy_score(y_val, y_pred_val),\n",
    "        \"PrecisionTrain\":precision_score(y_train, y_pred_train),\n",
    "        \"PrecisionTest\":precision_score(y_val, y_pred_val),\n",
    "        \"RecallTrain\":recall_score(y_train, y_pred_train),\n",
    "        \"RecallTest\":recall_score(y_val, y_pred_val),\n",
    "        \"AUCTrain\":roc_auc_score(y_train, y_pred_train),\n",
    "        \"AUCTest\":roc_auc_score(y_val, y_pred_val),\n",
    "    }\n",
    "    results.append(metadata)\n",
    "\n",
    "results_table = pd.DataFrame.from_records(results)\n",
    "\n",
    "#va a unas 30-40 combinaciones analizadas por minuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la combinación con el mejor valor en la métrica que nos interese\n",
    "num_fila=results_table['AUCTest'].argmax()\n",
    "results_table['Combination'].iloc[num_fila]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f68e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8db0d894",
   "metadata": {},
   "source": [
    "# Optimización computacional de la generación de combinaciones\n",
    "Aplicar el generador en el bucle for y ir guardando los resultados en una tabla de sqllite, de tal manera que si interrumpes el bucle pq aun no ha acabado puedes consultar los resultados que llevabas de la tabla de sqllite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DB with results\n",
    "connection = sqlite3.connect(\"data/results.db\")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS results(\n",
    "    Combination TEXT,\n",
    "    Hyperparameters TEXT,\n",
    "    AccuracyTrain REAL,\n",
    "    AccuracyTest REAL,\n",
    "    PrecisionTrain REAL,\n",
    "    PrecisionTest REAL,\n",
    "    RecallTrain REAL,\n",
    "    RecallTest REAL,\n",
    "    AUCTrain REAL,\n",
    "    AUCTest REAL)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b55e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo para reiniciar la tabla si no se quieren usar los resultados previos\n",
    "cursor.execute(\n",
    "    \"DELETE FROM results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ce9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example select\n",
    "cursor.execute(\n",
    "    \"SELECT * FROM results\"\n",
    ").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f290477-dd22-4267-91c3-e0a02708d052",
   "metadata": {
    "id": "4f290477-dd22-4267-91c3-e0a02708d052"
   },
   "outputs": [],
   "source": [
    "#RF pequeño, para evitar overfitting\n",
    "\n",
    "hyperparameters = {}\n",
    "'''n_estimators':10,  # Número reducido de árboles\n",
    "    'max_depth':5,  # Profundidad máxima limitada\n",
    "    'min_samples_split':20,  # Mayor número mínimo de muestras para dividir un nodo\n",
    "    'min_samples_leaf':10,\n",
    "    'max_features': 'auto',\n",
    "    'bootstrap': True,\n",
    "    'oob_score':True\n",
    "                  '''\n",
    "results = []\n",
    "\n",
    "for combi in tqdm(custom_combis_opt): #no falta la cross-validation?\n",
    "    model = RandomForestClassifier(**hyperparameters)\n",
    "    model.fit(x_train_s[combi], y_train)\n",
    "    y_pred_train = model.predict(x_train_s[combi])\n",
    "    y_pred_val = model.predict(x_val_s[combi])\n",
    "    metadata = {\n",
    "        \"Combination\":combi,\n",
    "        \"Hyperparameters\":hyperparameters,\n",
    "        \"AccuracyTrain\":accuracy_score(y_train, y_pred_train),\n",
    "        \"AccuracyTest\":accuracy_score(y_val, y_pred_val),\n",
    "        \"PrecisionTrain\":precision_score(y_train, y_pred_train),\n",
    "        \"PrecisionTest\":precision_score(y_test, y_pred_val),\n",
    "        \"RecallTrain\":recall_score(y_train, y_pred_train),\n",
    "        \"RecallTest\":recall_score(y_test, y_pred_val),\n",
    "        \"AUCTrain\":roc_auc_score(y_train, y_pred_train),\n",
    "        \"AUCTest\":roc_auc_score(y_test, y_pred_val),\n",
    "    }\n",
    "    cursor.execute(\n",
    "        f\"\"\"\n",
    "        INSERT INTO results VALUES\n",
    "        (\n",
    "            '{json.dumps(combi)}',\n",
    "            '{json.dumps(hyperparameters)}',\n",
    "            {metadata[\"AccuracyTrain\"]},\n",
    "            {metadata[\"AccuracyTest\"]},\n",
    "            {metadata[\"PrecisionTrain\"]},\n",
    "            {metadata[\"PrecisionTest\"]},\n",
    "            {metadata[\"RecallTrain\"]},\n",
    "            {metadata[\"RecallTest\"]},\n",
    "            {metadata[\"AUCTrain\"]},\n",
    "            {metadata[\"AUCTest\"]}\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "    results.append(metadata)\n",
    "\n",
    "results_table = pd.DataFrame.from_records(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table_sql = pd.read_sql(\"SELECT * FROM results\", connection)\n",
    "results_table_sql[\"Combination\"] = results_table_sql[\"Combination\"].apply(json.loads)\n",
    "results_table_sql[\"Hyperparameters\"] = results_table_sql[\"Hyperparameters\"].apply(json.loads)\n",
    "results_table_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499042c-7201-488e-bd25-73aa01fc3cd5",
   "metadata": {
    "id": "2499042c-7201-488e-bd25-73aa01fc3cd5"
   },
   "outputs": [],
   "source": [
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1337fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la combinación con el mejor valor en la métrica que nos interese\n",
    "num_fila=results_table_sql['AUCTest'].argmax()\n",
    "results_table_sql['Combination'].iloc[num_fila]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90008061",
   "metadata": {},
   "source": [
    "Quizá seria interesante reducir el tamaño del dataset a nivel de filas para agilizar el entrenamiento de estos pequeños modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd52445-379e-4539-b7ef-f57c2cc606c8",
   "metadata": {
    "id": "9cd52445-379e-4539-b7ef-f57c2cc606c8"
   },
   "outputs": [],
   "source": [
    "# Obtener la combinación con el mejor valor en la métrica que nos interese\n",
    "num_fila=results_table['AUCTest'].argmax()\n",
    "results_table['Combination'].iloc[num_fila]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ddfb6-69a0-47a3-85bc-768e69157c73",
   "metadata": {
    "id": "3f5ddfb6-69a0-47a3-85bc-768e69157c73"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04ab9a-bb77-423b-a205-e42860769794",
   "metadata": {
    "id": "5e04ab9a-bb77-423b-a205-e42860769794"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca053c87-554a-4fc6-9145-3002ccbb1be0",
   "metadata": {
    "id": "ca053c87-554a-4fc6-9145-3002ccbb1be0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a7cd8-3743-49f6-a3af-771477ae01a0",
   "metadata": {
    "id": "d86a7cd8-3743-49f6-a3af-771477ae01a0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b812cd-47a9-4121-b3f0-742166c54555",
   "metadata": {
    "id": "63b812cd-47a9-4121-b3f0-742166c54555"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d65168-3a4c-41d9-8e07-cb08e489e2d3",
   "metadata": {
    "id": "31d65168-3a4c-41d9-8e07-cb08e489e2d3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403378d-94bf-4f95-a74f-a79a6605c394",
   "metadata": {
    "id": "5403378d-94bf-4f95-a74f-a79a6605c394"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f53f2a-0d5d-4572-be8d-b73361381534",
   "metadata": {
    "id": "22f53f2a-0d5d-4572-be8d-b73361381534"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c2791-b01a-4fe2-8a3f-76a6cd155ce8",
   "metadata": {
    "id": "5d9c2791-b01a-4fe2-8a3f-76a6cd155ce8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482c79f-f28e-4391-b0bf-93d6175cef1d",
   "metadata": {
    "id": "5482c79f-f28e-4391-b0bf-93d6175cef1d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef008ad7-a391-4a87-acd9-857d6d1c8b4e",
   "metadata": {
    "id": "ef008ad7-a391-4a87-acd9-857d6d1c8b4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811de77-f05b-407b-a942-7ff04e399e9d",
   "metadata": {
    "id": "8811de77-f05b-407b-a942-7ff04e399e9d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2564a-188b-44c1-b84d-9ffc5910b932",
   "metadata": {
    "id": "e2c2564a-188b-44c1-b84d-9ffc5910b932",
    "outputId": "e54a48f0-598f-4fb0-d524-b634bf1361bd"
   },
   "outputs": [],
   "source": [
    "## mirar otro número de clusters: 5\n",
    "\n",
    "unicos5 = df_standard_T['Cluster_5'].unique()\n",
    "\n",
    "diccionario5 = {}\n",
    "\n",
    "for valor in unicos5:\n",
    "    filas = df_standard_T.index[df_standard_T['Cluster_5'] == valor].tolist()\n",
    "    diccionario5[valor] = filas\n",
    "\n",
    "# Ver el diccionario\n",
    "for clave, valor in diccionario5.items():\n",
    "    print(f'Valor: {clave} - Filas: {valor}')\n",
    "\n",
    "df_cluster5 = pd.DataFrame.from_dict(diccionario5, orient='index')\n",
    "df_cluster5\n",
    "#este parece que tiene menos sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e6cdf-fcf1-478a-85f9-d3d874986afa",
   "metadata": {
    "id": "3b2e6cdf-fcf1-478a-85f9-d3d874986afa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
